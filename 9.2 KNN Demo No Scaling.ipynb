{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Classification Using KNN (Without Scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> [Breast Cancer Diagnostic] </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main classifications of tumors. One is known as benign and the other as malignant. A benign tumor is a tumor that does not invade its surrounding tissue or spread around the body. A malignant tumor is a tumor that may invade its surrounding tissue or spread around the body."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target it to train a KNN Regression model that can predict whether the cancer is benign (B) or malignant (M)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "<br>1) ID number \n",
    "<br>2) Diagnosis (M = malignant, B = benign) \n",
    "<br>3-32) Ten real-valued features are computed for each cell nucleus: \n",
    "<br>a) radius (mean of distances from center to points on the perimeter) \n",
    "<br>b) texture (standard deviation of gray-scale values) \n",
    "<br>c) perimeter \n",
    "<br>d) area \n",
    "<br>e) smoothness (local variation in radius lengths) \n",
    "<br>f) compactness (perimeter^2 / area - 1.0) \n",
    "<br>g) concavity (severity of concave portions of the contour) \n",
    "<br>h) concave points (number of concave portions of the contour) \n",
    "<br>i) symmetry \n",
    "<br>j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "**`'Diagnosis'`** column is the **Dependent Variable or target column** because we want our algorithm to predict this class.\n",
    "\n",
    "**`'1,3-32'`** are your **Features or Independent Variables** which will help you predict the Benign/Malignant class. Vary any one of them and it is going to affect your Diagnostic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CSV file  ../Data/Breast_Cancer_Diagnostic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loding the dataset into pandas dataframe.\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/diksha-cl/Data-files/master/Breast_Cancer_Diagnostic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain the 10 features and the target variable.\n",
    "df = df[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean','diagnosis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for nulls.\n",
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataframe of features (X) and the target (Y) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the features to a variable X\n",
    "# X is created by simply dropping the diagnosis column and retaining all others\n",
    "X = df.drop('diagnosis', axis = 1)\n",
    "\n",
    "# Load the target variable to y\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Test Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**> Train-Test split -** We split our data into two parts, namely, the train set and the test set (ideally its a 70-30 train-test split which is upto you). We then try to build our function f(x) (aka model) using the train set and see how well it does on the test set.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Instance of the classifier and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create an instance for the KNN model and then train it with the training set.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model using the training sets. This does nothing other than store the points in \n",
    "# some internal data structure.\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual Predictions\n",
       "421      B           B\n",
       "47       M           B\n",
       "292      B           B\n",
       "186      M           M\n",
       "414      M           M"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting predictions from the model \n",
    "y_test_hat = model.predict(X_test)\n",
    "\n",
    "# Compare the predicted values with the actuals.\n",
    "Results = pd.DataFrame({'Actual': y_test})\n",
    "column = pd.DataFrame({'Predictions': y_test_hat})\n",
    "Results = Results.join(column.set_index(Results.index))\n",
    "Results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98 10]\n",
      " [13 50]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    " \n",
    "cm = confusion_matrix(y_test, y_test_hat)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> DOMAIN KNOWLEDGE : </b> \n",
    "<br>It plays a very big role in solving a machine learning problem. If you know your data in and out thats when you would be getting best results. For this instance we would want to minimise FN more than anything else. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.7936507936507936\n",
      "precision: 0.8333333333333334\n",
      "specificity: 0.9074074074074074\n"
     ]
    }
   ],
   "source": [
    "# Assigning Variables for convinience\n",
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TP = cm[1][1]\n",
    "\n",
    "recall = TP / float(FN + TP)\n",
    "print(\"recall:\", recall)\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "print(\"precision:\", precision)\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "print(\"specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat of KNN with K=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100   8]\n",
      " [ 14  49]]\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "# Train the model using the training sets. \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Getting predictions from the model \n",
    "y_test_hat = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_hat)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.7777777777777778\n",
      "precision: 0.8596491228070176\n",
      "specificity: 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "# Assigning Variables for convinience\n",
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TP = cm[1][1]\n",
    "\n",
    "recall = TP / float(FN + TP)\n",
    "print(\"recall:\", recall)\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "print(\"precision:\", precision)\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "print(\"specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
